{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL0-SUYRm0zu"
      },
      "source": [
        "# Machine Learning Lab - Steel Industry\n",
        "## Part 4: Anomaly Detection with Deep Learning\n",
        "\n",
        "In this part, we will use convolutional neural networks (CNN) with PyTorch to detect anomalies in industrial images, using the MVTec AD dataset.\n",
        "\n",
        "### Objectives:\n",
        "- Understand the principles of anomaly detection with Deep Learning\n",
        "- Implement a CNN model with PyTorch\n",
        "- Evaluate and visualize the results\n",
        "\n",
        "### Methods covered:\n",
        "- Convolutional autoencoders with PyTorch\n",
        "- Transfer Learning\n",
        "- Anomaly detection metrics\n",
        "\n",
        "⚠️ **Important**: Before starting, activate the GPU:\n",
        "1. Menu \"Runtime\" > \"Change runtime type\"\n",
        "2. Select \"T4 GPU\" in the \"Hardware accelerator\" dropdown\n",
        "3. Click \"Save\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSIpCzwNm7oB"
      },
      "outputs": [],
      "source": [
        "# Import des packages nécessaires\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "import torch.distributions as dist\n",
        "\n",
        "# Vérification du GPU\n",
        "print(\"GPU disponible :\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Nom du GPU :\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Configuration\n",
        "sns.set_theme(style='whitegrid')\n",
        "%matplotlib inline\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Utilisation de : {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiGWKlp9m93B"
      },
      "source": [
        "### 1. Loading and preparing the MVTec AD data (Bottle dataset)\n",
        "\n",
        "The MVTec AD dataset contains industrial images of different objects, with normal and abnormal examples.\n",
        "\n",
        "❓ Questions about the data:\n",
        "- Why use only \"normal\" images for training?\n",
        "- How does this reflect industrial reality?\n",
        "- What is the purpose of data augmentation in this context?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HORH9jwWm_rA"
      },
      "outputs": [],
      "source": [
        "# Création du dossier pour le dataset\n",
        "!mkdir -p mvtec_data\n",
        "\n",
        "# Téléchargement uniquement du dataset bottle\n",
        "!wget -P mvtec_data https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/bottle.tar.xz\n",
        "!cd mvtec_data && tar -xf bottle.tar.xz\n",
        "\n",
        "# Vérification de la structure du dataset\n",
        "print(\"\\nStructure du dataset :\")\n",
        "!ls -R mvtec_data/bottle | grep \":$\" | sed -e 's/:$//' -e 's/[^-][^\\/]*\\//  /g' -e 's/^/  /'\n",
        "\n",
        "# Création d'un Dataset personnalisé\n",
        "class MVTecDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Définition des transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Réduction de 256x256 à 128x128\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=3)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Réduction de 256x256 à 128x128\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=3)\n",
        "])\n",
        "\n",
        "# Création des datasets avec les nouveaux chemins\n",
        "train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=train_transform)\n",
        "test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=test_transform)\n",
        "# /!\\ Complétez les '...' pour créer un test_anomaly_dataset qui se source dans les images mvtec_data/bottle/test/broken_large /!\\\n",
        "test_anomaly_dataset = ...\n",
        "\n",
        "# Création des dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Batch size de 32 à 16\n",
        "test_normal_loader = DataLoader(test_normal_dataset, batch_size=16, shuffle=False)\n",
        "test_anomaly_loader = DataLoader(test_anomaly_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"\\nNombre d'images :\")\n",
        "print(f\"Training (normal) : {len(train_dataset)}\")\n",
        "print(f\"Test (normal) : {len(test_normal_dataset)}\")\n",
        "print(f\"Test (anomalies) : {len(test_anomaly_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh5uECbKnfs1"
      },
      "source": [
        "### 2. Creating the Autoencoder model with PyTorch\n",
        "\n",
        "❓ Questions about the architecture:\n",
        "- Why choose an encoder-decoder architecture?\n",
        "- What does the latent space represent in our industrial context?\n",
        "- How does the bottleneck force the learning of relevant features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NumzTqztngh3"
      },
      "outputs": [],
      "source": [
        "class ImprovedAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedAutoencoder, self).__init__()\n",
        "\n",
        "        # Réduction du nombre de filtres\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),  # 64 -> 32\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),  # 128 -> 64\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),  # 256 -> 128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),  # 512 -> 256\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # Decoder (mise à jour des dimensions en conséquence)\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p3)\n",
        "\n",
        "        # Decoding avec skip connections\n",
        "        d3 = self.up3(b)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        return d1, b\n",
        "\n",
        "# Loss améliorée avec composante structurelle\n",
        "class EnhancedLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3):\n",
        "        super(EnhancedLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.l1 = nn.L1Loss()\n",
        "\n",
        "    def forward(self, output, target, encoded_output, encoded_target):\n",
        "        # MSE pour la reconstruction globale\n",
        "        mse_loss = self.mse(output, target)\n",
        "\n",
        "        # L1 pour les détails fins\n",
        "        l1_loss = self.l1(output, target)\n",
        "\n",
        "        # MSE sur l'espace latent\n",
        "        # /!\\ Complétez les '...' pour créer une feature loss qui est une mse entre encoded_output et encoded_target /!\\\n",
        "        feature_loss = ...\n",
        "\n",
        "        # Combinaison des losses\n",
        "        total_loss = self.alpha * (0.5 * mse_loss + 0.5 * l1_loss) + self.beta * feature_loss\n",
        "        return total_loss\n",
        "\n",
        "# Mise à jour des datasets avec les nouvelles transformations\n",
        "train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=train_transform)\n",
        "test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=test_transform)\n",
        "test_anomaly_dataset = MVTecDataset('mvtec_data/bottle/test/broken_large', transform=test_transform)\n",
        "\n",
        "# Création et déplacement du modèle sur le device approprié\n",
        "model = ImprovedAutoencoder().to(device)\n",
        "criterion = EnhancedLoss(alpha=0.7, beta=0.3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kajC2Efd2BXh"
      },
      "outputs": [],
      "source": [
        "# Fonction d'entraînement améliorée\n",
        "def train_improved_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass avec encoded features\n",
        "        reconstructed, encoded = model(batch)\n",
        "        with torch.no_grad():\n",
        "            _, target_encoded = model(batch)\n",
        "\n",
        "        # Calcul de la loss combinée\n",
        "        loss = criterion(reconstructed, batch, encoded, target_encoded.detach())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Libération explicite de la mémoire\n",
        "        del reconstructed, encoded, target_encoded\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Entraînement avec early stopping\n",
        "n_epochs = 100\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_improved_epoch(model, train_loader, criterion, optimizer)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        patience_counter = 0\n",
        "        # Sauvegarder le meilleur modèle\n",
        "        torch.save(model.state_dict(), 'best_autoencoder.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f'Early stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss:.4f}')\n",
        "\n",
        "# Chargement du meilleur modèle pour l'évaluation\n",
        "model.load_state_dict(torch.load('best_autoencoder.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvxp8R1Tno7i"
      },
      "source": [
        "### 3. Evaluation and anomaly detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfWeK1SdnpnA"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_reconstruction_error(model, dataloader):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        reconstructed, encoded = model(batch)  # Déballage du tuple\n",
        "        error = torch.mean((batch - reconstructed) ** 2, dim=(1,2,3))\n",
        "        errors.extend(error.cpu().numpy())\n",
        "\n",
        "    return np.array(errors)\n",
        "\n",
        "# Calcul des erreurs de reconstruction\n",
        "normal_errors = compute_reconstruction_error(model, test_normal_loader)\n",
        "anomaly_errors = compute_reconstruction_error(model, test_anomaly_loader)\n",
        "\n",
        "# Visualisation de la distribution des erreurs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(normal_errors, bins=50, alpha=0.5, label='Normal')\n",
        "plt.hist(anomaly_errors, bins=50, alpha=0.5, label='Anomalie')\n",
        "plt.title('Distribution des erreurs de reconstruction')\n",
        "plt.xlabel('MSE')\n",
        "plt.ylabel('Nombre d\\'échantillons')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calcul et affichage de la courbe ROC\n",
        "y_true = np.concatenate([np.zeros(len(normal_errors)), np.ones(len(anomaly_errors))])\n",
        "# /!\\ Complétez les '...' pour créer y_scores représentant, composé de la concaténation des erreurs normales (normal_errors) et des anomalies (anomaly_errors) /!\\\n",
        "y_scores = ...\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taux de faux positifs')\n",
        "plt.ylabel('Taux de vrais positifs')\n",
        "plt.title('Courbe ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq82Yf0tns55"
      },
      "source": [
        "### 4. Results visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQl2ZWupnuXI"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def plot_results(model, dataloader, n=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Récupération d'un batch\n",
        "    batch = next(iter(dataloader))\n",
        "    batch = batch[:n].to(device)\n",
        "    reconstructed, _ = model(batch)\n",
        "\n",
        "    # Conversion pour affichage\n",
        "    batch = batch.cpu()\n",
        "    reconstructed = reconstructed.cpu()\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        img = batch[i].permute(1, 2, 0).numpy()\n",
        "        plt.imshow(img, cmap='gray')  # Utiliser cmap='gray' pour les images en niveaux de gris\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Reconstruction\n",
        "        plt.subplot(2, n, i + n + 1)\n",
        "        img = reconstructed[i].permute(1, 2, 0).numpy()\n",
        "        plt.imshow(img, cmap='gray')  # Utiliser cmap='gray' pour les images en niveaux de gris\n",
        "        # /!\\ Complétez les '...' pour ajouter le titre 'Reconstruction' au graphe /!\\\n",
        "        plt....\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualisation des résultats\n",
        "print(\"Exemples normaux :\")\n",
        "plot_results(model, test_normal_loader)\n",
        "\n",
        "print(\"\\nExemples avec anomalies :\")\n",
        "plot_results(model, test_anomaly_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhHoD474nxPH"
      },
      "source": [
        "❓ Questions about the classic autoencoder:\n",
        "\n",
        "- Why are the reconstructions almost identical to the original images?\n",
        "- How to explain the small difference between the reconstruction errors of normal and abnormal images?\n",
        "- Did the autoencoder really learn the \"normal\" features of the bottles?\n",
        "- Is this \"too good\" reconstruction desirable for anomaly detection?\n",
        "- What happens if the autoencoder simply learns to \"copy\" the input?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANSE54Hl8OYF"
      },
      "source": [
        "### 5. Improvement with a Variational Autoencoder (VAE)\n",
        "\n",
        "To improve anomaly detection, we will use a VAE which should:\n",
        "- Better regularize the latent space\n",
        "- Learn a more robust distribution of normal images\n",
        "- Better \"repair\" anomalies in the reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1GDxHuw8PN_"
      },
      "outputs": [],
      "source": [
        "vae_train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x)\n",
        "])\n",
        "\n",
        "# /!\\ Complétez les '...' pour transformer l'image de départ en résolution 128x128n pendant la transformation /!\\\n",
        "vae_test_transform = transforms.Compose([\n",
        "    ...,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x)\n",
        "])\n",
        "\n",
        "# Création de nouveaux datasets pour le VAE\n",
        "vae_train_dataset = MVTecDataset('mvtec_data/bottle/train/good', transform=vae_train_transform)\n",
        "vae_test_normal_dataset = MVTecDataset('mvtec_data/bottle/test/good', transform=vae_test_transform)\n",
        "vae_test_anomaly_dataset = MVTecDataset('mvtec_data/bottle/test/broken_large', transform=vae_test_transform)\n",
        "\n",
        "# Création des dataloaders pour le VAE\n",
        "vae_train_loader = DataLoader(vae_train_dataset, batch_size=16, shuffle=True)\n",
        "vae_test_normal_loader = DataLoader(vae_test_normal_dataset, batch_size=16, shuffle=False)\n",
        "vae_test_anomaly_loader = DataLoader(vae_test_anomaly_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Définition du VAE\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=64):  # Dimension latente réduite\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder inspiré de l'autoencoder qui fonctionnait bien\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Premier bloc\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Deuxième bloc\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Troisième bloc\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Projections mu et logvar\n",
        "        self.fc_mu = nn.Linear(128 * 16 * 16, latent_dim)\n",
        "        self.fc_var = nn.Linear(128 * 16 * 16, latent_dim)\n",
        "\n",
        "        # Decoder symétrique\n",
        "        self.decoder_input = nn.Linear(latent_dim, 128 * 16 * 16)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Premier bloc\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Deuxième bloc\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Troisième bloc\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Couche finale\n",
        "            nn.Conv2d(32, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc_mu(x), self.fc_var(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return mu + eps * std\n",
        "        return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.decoder_input(z)\n",
        "        z = z.view(z.size(0), 128, 16, 16)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# Loss function avec un très faible poids KL\n",
        "class VAELoss(nn.Module):\n",
        "    def __init__(self, kld_weight=0.0001):  # Poids KL très faible\n",
        "        super().__init__()\n",
        "        self.kld_weight = kld_weight\n",
        "\n",
        "    def forward(self, recon_x, x, mu, logvar):\n",
        "        recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
        "        kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return recon_loss + self.kld_weight * kld_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiniRoFV8ZO2"
      },
      "outputs": [],
      "source": [
        "# Paramètres d'entraînement\n",
        "vae_model = VariationalAutoencoder().to(device)\n",
        "vae_criterion = VAELoss()\n",
        "vae_optimizer = optim.Adam(vae_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Fonction d'entraînement du VAE\n",
        "def train_vae_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon_batch, mu, logvar = model(batch)\n",
        "        loss = criterion(recon_batch, batch, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Entraînement du VAE\n",
        "print(\"Début de l'entraînement du VAE...\")\n",
        "n_epochs = 100\n",
        "best_loss = float('inf')\n",
        "vae_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_vae_epoch(vae_model, vae_train_loader, vae_criterion, vae_optimizer)\n",
        "    vae_losses.append(loss)\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(vae_model.state_dict(), 'best_vae.pth')\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO9QpMPz8cn3"
      },
      "outputs": [],
      "source": [
        "# Visualisation des résultats du VAE\n",
        "@torch.no_grad()\n",
        "def plot_vae_results(model, dataloader, n=5):\n",
        "    model.eval()\n",
        "    batch = next(iter(dataloader))\n",
        "    batch = batch[:n].to(device)\n",
        "    recon, _, _ = model(batch)\n",
        "\n",
        "    batch = batch.cpu()\n",
        "    recon = recon.cpu()\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(batch[i].permute(1, 2, 0), cmap='gray')\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Reconstruction\n",
        "        plt.subplot(2, n, i + n + 1)\n",
        "        plt.imshow(recon[i].permute(1, 2, 0), cmap='gray')\n",
        "        plt.title('Reconstruction VAE')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nRésultats du VAE sur les images normales :\")\n",
        "plot_vae_results(vae_model, vae_test_normal_loader)\n",
        "\n",
        "print(\"\\nRésultats du VAE sur les images avec anomalies :\")\n",
        "# /!\\ Complétez les '...' pour afficher les images d'entrée et reconstruites (vae_test_anomaly_loader), via le variational auto-encoder  /!\\\n",
        "plot_vae_results(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWWpivq39Hsj"
      },
      "source": [
        "❓ Questions about the advantages of the VAE:\n",
        "- Why are VAE reconstructions more \"blurry\"?\n",
        "- How is this \"blurriness\" actually an advantage for anomaly detection?\n",
        "- How does the VAE handle unusual features differently?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PINXpbz1DhDP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_vae(model, normal_loader, anomaly_loader):\n",
        "    model.eval()\n",
        "\n",
        "    normal_errors = []\n",
        "    anomaly_errors = []\n",
        "\n",
        "    # Pour les images normales\n",
        "    for batch in normal_loader:\n",
        "        batch = batch.to(device)\n",
        "        recon, mu, logvar = model(batch)\n",
        "        # Erreur de reconstruction pixel par pixel\n",
        "        recon_error = F.mse_loss(recon, batch, reduction='none')\n",
        "        # Moyenne sur les canaux uniquement (garde les dimensions spatiales)\n",
        "        recon_error = recon_error.mean(dim=1)\n",
        "        # Maximum local pour détecter les anomalies locales\n",
        "        recon_error = F.max_pool2d(recon_error, kernel_size=3, stride=1, padding=1)\n",
        "        # Moyenne sur l'image\n",
        "        recon_error = recon_error.mean(dim=(1,2))\n",
        "\n",
        "        normal_errors.extend(recon_error.cpu().numpy())\n",
        "\n",
        "    # Pour les images avec anomalies\n",
        "    for batch in anomaly_loader:\n",
        "        batch = batch.to(device)\n",
        "        recon, mu, logvar = model(batch)\n",
        "        recon_error = F.mse_loss(recon, batch, reduction='none')\n",
        "        recon_error = recon_error.mean(dim=1)\n",
        "        recon_error = F.max_pool2d(recon_error, kernel_size=3, stride=1, padding=1)\n",
        "        recon_error = recon_error.mean(dim=(1,2))\n",
        "\n",
        "        anomaly_errors.extend(recon_error.cpu().numpy())\n",
        "\n",
        "    # Normalisation des erreurs\n",
        "    all_errors = np.concatenate([normal_errors, anomaly_errors])\n",
        "    error_mean = np.mean(all_errors)\n",
        "    error_std = np.std(all_errors)\n",
        "    normal_errors = (normal_errors - error_mean) / error_std\n",
        "    anomaly_errors = (anomaly_errors - error_mean) / error_std\n",
        "\n",
        "    # Calcul des métriques\n",
        "    y_true = np.concatenate([np.zeros(len(normal_errors)), np.ones(len(anomaly_errors))])\n",
        "    y_scores = np.concatenate([normal_errors, anomaly_errors])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    return {\n",
        "        'normal_errors': normal_errors,\n",
        "        'anomaly_errors': anomaly_errors,\n",
        "        'AUC': roc_auc,\n",
        "        'FPR': fpr,\n",
        "        'TPR': tpr\n",
        "    }\n",
        "\n",
        "# Visualisation améliorée des résultats\n",
        "metrics = evaluate_vae(vae_model, vae_test_normal_loader, vae_test_anomaly_loader)\n",
        "\n",
        "# Courbe ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(metrics['FPR'], metrics['TPR'], color='darkorange', lw=2,\n",
        "         label=f'ROC curve (AUC = {metrics[\"AUC\"]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taux de faux positifs')\n",
        "plt.ylabel('Taux de vrais positifs')\n",
        "plt.title('Courbe ROC du VAE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution des erreurs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(metrics['normal_errors'], bins=50, alpha=0.7, label='Normal', density=True)\n",
        "plt.hist(metrics['anomaly_errors'], bins=50, alpha=0.7, label='Anomalie', density=True)\n",
        "plt.title('Distribution des erreurs de reconstruction normalisées')\n",
        "plt.xlabel('Erreur de reconstruction (normalisée)')\n",
        "plt.ylabel('Densité')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "# /!\\ Complétez les '...' pour afficher le graphe /!\\\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0kN16Cm_c30"
      },
      "source": [
        "### Analysis of Anomaly Reconstructions\n",
        "\n",
        "❓ In-depth questions:\n",
        "- How does the VAE \"force\" the learning of useful features?\n",
        "- Why is the normal distribution constraint in the latent space important?\n",
        "- How could anomaly detection be further improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqYPZi4Bc7g"
      },
      "source": [
        "### Conclusion and perspectives\n",
        "❓ Final questions:\n",
        "- Which model should be chosen for a real industrial application?\n",
        "- How to adapt these models to other types of anomalies?\n",
        "- What further improvements could be made?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
